{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "# project_dir_path = '/home/onoue/ws/lukasiewicz_1'\n",
    "project_dir_path = '/Users/keisukeonoue/ws/lukasiewicz_1/'\n",
    "sys.path.append(project_dir_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.rulefit import RuleFitClassifier\n",
    "from src.setup_problem_primal_modular import Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleFitClassifier のなかの tree generator (random forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any, List\n",
    "import json\n",
    "\n",
    "# from .setup_problem import Setup\n",
    "class Setup_:\n",
    "    \"\"\"\n",
    "    型ヒント用（circular import の回避のため）\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from src.misc import is_symbol\n",
    "from src.operators import negation\n",
    "\n",
    "\n",
    "\n",
    "class EvaluateModelRuleFit:\n",
    "    def __init__(self,\n",
    "                 path_discretized: str,\n",
    "                 model: object,\n",
    "                 KB_origin: List[List[str]],\n",
    "                 random_state: int,\n",
    "                 n_splits: int,\n",
    "                 train_index: np.ndarray,\n",
    "                 test_index: np.ndarray,\n",
    "                 name: str = None,\n",
    "                 note: str = None) -> None:\n",
    "\n",
    "        self.path_discretized = path_discretized\n",
    "        self.model = model\n",
    "        self.KB_origin = KB_origin\n",
    "        self.random_state = random_state \n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        self.train_index = train_index\n",
    "        self.test_index = test_index\n",
    "\n",
    "        self.result_dict = {\n",
    "            'name'     : name,\n",
    "            'note'     : note,\n",
    "            'Accuracy' : None,\n",
    "            'Precision': None,\n",
    "            'Recall'   : None,\n",
    "            'F1-score' : None,\n",
    "            'Auc'      : None,\n",
    "            'len_U'    : None,\n",
    "            'Rules'    : {'violation': 0, 'total': len(self.KB_origin)},\n",
    "            'Rules_detail': {}\n",
    "        }\n",
    "\n",
    "    def calculate_scores(self) -> None:\n",
    "        data = pd.read_csv(self.path_discretized, index_col=0)\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "        X = data.drop('Outcome', axis=1)\n",
    "        y = data['Outcome']\n",
    "        y.replace(0, -1, inplace=True)\n",
    "\n",
    "        X_train, y_train = X.loc[self.train_index, :], y.loc[self.train_index]\n",
    "        X_test, y_test = X.loc[self.test_index, :], y.loc[self.test_index]\n",
    "\n",
    "        feature_names = list(X_train.columns)\n",
    "        X_train = X_train.values\n",
    "        X_test  = X_test.values\n",
    "        y_train = y_train.values\n",
    "        y_test  = y_test.values        \n",
    "        self.model.fit(X_train, y_train, feature_names=feature_names)\n",
    "\n",
    "\n",
    "        y_pred = self.model.tree_generator.predict(X_test)\n",
    "\n",
    "        y_pred_interpreted = np.where(y_pred == 0, -1, y_pred)\n",
    "        \n",
    "        y_pred = self.model.tree_generator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 精度等の一般的な評価指標の計算\n",
    "        accuracy = accuracy_score(y_test, y_pred_interpreted)\n",
    "        precision = precision_score(y_test, y_pred_interpreted)\n",
    "        recall = recall_score(y_test, y_pred_interpreted)\n",
    "        f1 = f1_score(y_test, y_pred_interpreted)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        self.result_dict['Accuracy'] = float(accuracy)\n",
    "        self.result_dict['Precision'] = float(precision)\n",
    "        self.result_dict['Recall'] = float(recall)\n",
    "        self.result_dict['F1-score'] = float(f1)\n",
    "        self.result_dict['Auc'] = float(roc_auc)\n",
    "        \n",
    "        # ルール違反\n",
    "        rules_tmp = []\n",
    "        for rule in self.KB_origin:\n",
    "            if \"Outcome\" in rule:\n",
    "                tmp = {}\n",
    "                for idx, item in enumerate(rule):\n",
    "                    if not is_symbol(item):\n",
    "                        if idx == 0 or rule[idx - 1] != '¬':\n",
    "                            tmp[item] = 1\n",
    "                        elif item != \"Outcome\":\n",
    "                            tmp[item] = 0\n",
    "                        else:\n",
    "                            tmp[item] = -1\n",
    "                rules_tmp.append(tmp)\n",
    "\n",
    "        \n",
    "        X_test = pd.DataFrame(X_test, columns=feature_names, index=self.test_index)\n",
    "        y_pred_interpreted = pd.DataFrame(y_pred_interpreted, index=self.test_index)\n",
    "        \n",
    "\n",
    "        for i, rule in enumerate(rules_tmp):\n",
    "            outcome = rule[\"Outcome\"]\n",
    "            condition = \" & \".join([f\"{column} == {value}\" for column, value in rule.items() if column != \"Outcome\"])\n",
    "\n",
    "            tmp = y_pred_interpreted.loc[X_test.query(condition).index]\n",
    "\n",
    "            violation_bool = 1 if int((tmp != outcome).sum().iloc[0]) >= 1 else 0\n",
    "            self.result_dict['Rules']['violation'] += violation_bool\n",
    "            self.result_dict['Rules_detail'][i] = {\n",
    "                'rule': \" \".join(self.KB_origin[i]),\n",
    "                'violation': violation_bool,\n",
    "            }\n",
    "\n",
    "    def save_result_as_json(self, file_path) -> None:\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(self.result_dict, f, indent=4)\n",
    "\n",
    "    def evaluate(self, save_file_path: str = './result_1.json') -> None:\n",
    "        self.calculate_scores()\n",
    "        self.save_result_as_json(file_path=save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_rules took 0.0004918575286865234 seconds!\n",
      "24\n",
      "['Pregnancies_Low', '→', '¬', 'Outcome']\n",
      "['Pregnancies_High', '→', 'Outcome']\n",
      "['Glucose_Low', '→', '¬', 'Outcome']\n",
      "['Glucose_High', '→', 'Outcome']\n",
      "['BMI_Low', '→', '¬', 'Outcome']\n",
      "['BMI_Medium', '→', 'Outcome']\n",
      "['DiabetesPedigreeFunction_Low', '→', '¬', 'Outcome']\n",
      "['Age_Low', '→', '¬', 'Outcome']\n",
      "['Age_Medium', '→', 'Outcome']\n",
      "['¬', 'Pregnancies_Medium', '⊗', 'Glucose_High', '⊗', '¬', 'BMI_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Low', '⊗', 'BMI_Medium', '→', 'Outcome']\n",
      "['¬', 'Glucose_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Low', '⊗', 'Age_Medium', '⊗', 'BloodPressure_Medium', '⊗', '¬', 'BMI_Low', '⊗', 'Glucose_Medium', '→', 'Outcome']\n",
      "['¬', 'Glucose_High', '⊗', '¬', 'Glucose_Low', '⊗', '¬', 'Pregnancies_High', '⊗', 'DiabetesPedigreeFunction_Low', '⊗', '¬', 'BloodPressure_Medium', '⊗', '¬', 'BloodPressure_Low', '⊗', '¬', 'Age_Low', '⊗', '¬', 'SkinThickness_Medium', '→', '¬', 'Outcome']\n",
      "['¬', 'BMI_Low', '⊗', 'Glucose_Medium', '⊗', '¬', 'Pregnancies_High', '⊗', '¬', 'SkinThickness_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Medium', '⊗', '¬', 'BloodPressure_High', '⊗', '¬', 'BMI_High', '⊗', '¬', 'BloodPressure_Low', '⊗', 'Pregnancies_Low', '⊗', 'SkinThickness_Medium', '→', '¬', 'Outcome']\n",
      "['BMI_Medium', '⊗', 'Glucose_High', '⊗', '¬', 'BloodPressure_Medium', '→', 'Outcome']\n",
      "['¬', 'Glucose_Low', '⊗', '¬', 'Glucose_Medium', '⊗', '¬', 'BloodPressure_Medium', '⊗', '¬', 'Pregnancies_Medium', '⊗', '¬', 'Age_Medium', '⊗', '¬', 'BMI_Low', '→', 'Outcome']\n",
      "['¬', 'Glucose_High', '⊗', '¬', 'Pregnancies_Low', '⊗', 'Glucose_Medium', '⊗', 'BloodPressure_High', '⊗', 'Pregnancies_Medium', '⊗', 'SkinThickness_Low', '→', '¬', 'Outcome']\n",
      "['¬', 'Glucose_High', '⊗', 'BMI_Low', '⊗', 'Age_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Medium', '⊗', 'Pregnancies_Low', '→', '¬', 'Outcome']\n",
      "['Pregnancies_High', '⊗', '¬', 'DiabetesPedigreeFunction_Low', '⊗', '¬', 'BMI_Low', '→', 'Outcome']\n",
      "['BMI_Low', '⊗', 'Pregnancies_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Low', '⊗', '¬', 'BloodPressure_High', '→', '¬', 'Outcome']\n",
      "['¬', 'BMI_Low', '⊗', '¬', 'DiabetesPedigreeFunction_Low', '⊗', '¬', 'Glucose_High', '⊗', '¬', 'Age_Low', '⊗', 'Pregnancies_High', '→', 'Outcome']\n",
      "['¬', 'BMI_Medium', '⊗', 'BMI_High', '⊗', 'Age_Low', '⊗', '¬', 'SkinThickness_Low', '⊗', '¬', 'BloodPressure_High', '⊗', 'SkinThickness_High', '⊗', '¬', 'Glucose_Low', '⊗', 'BloodPressure_Medium', '→', '¬', 'Outcome']\n",
      "['¬', 'BMI_Low', '⊗', 'Glucose_High', '⊗', '¬', 'Pregnancies_High', '⊗', '¬', 'DiabetesPedigreeFunction_Medium', '⊗', '¬', 'BloodPressure_Medium', '→', 'Outcome']\n",
      "['BMI_High', '⊗', '¬', 'Pregnancies_Medium', '⊗', '¬', 'DiabetesPedigreeFunction_High', '⊗', '¬', 'Glucose_Low', '⊗', 'BloodPressure_High', '→', 'Outcome']\n",
      "['¬', 'Age_Medium', '⊗', '¬', 'BMI_High', '⊗', '¬', 'DiabetesPedigreeFunction_High', '⊗', '¬', 'BloodPressure_Medium', '⊗', '¬', 'SkinThickness_Medium', '⊗', '¬', 'Age_High', '→', '¬', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "# KB_origin の生成\n",
    "data_dir_path = os.path.join(project_dir_path, 'inputs/pima_indian_diabetes_cv_3/fold_0')\n",
    "file_list = os.listdir(os.path.join(data_dir_path, 'train'))\n",
    "\n",
    "L_files = [filename for filename in file_list \n",
    "           if filename.startswith('L') and filename.endswith('.csv')]\n",
    "\n",
    "U_files = [filename for filename in file_list \n",
    "           if filename.startswith('U') and filename.endswith('.csv')]\n",
    "\n",
    "file_names_dict = {\n",
    "    'supervised': L_files,\n",
    "    'unsupervised': U_files,\n",
    "    'rule': ['rules_3.txt']\n",
    "}\n",
    "\n",
    "problem_instance = Setup(data_dir_path, \n",
    "                         file_names_dict, \n",
    "                         None)\n",
    "\n",
    "problem_instance.load_rules()\n",
    "\n",
    "print(len(problem_instance.KB_origin))\n",
    "\n",
    "for formula in problem_instance.KB_origin:\n",
    "    print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_discretized = \"./data/diabetes_discretized.csv\"\n",
    "data = pd.read_csv(path_discretized, index_col=0)\n",
    "data = data.reset_index(drop=True)\n",
    "X = data.drop('Outcome', axis=1)    \n",
    "y = data['Outcome']\n",
    "y.replace(0, -1, inplace=True)\n",
    "\n",
    "random_state = 42\n",
    "n_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    rfmode = 'classify'\n",
    "    tree_generator = RandomForestClassifier(random_state=random_state)\n",
    "    # ここでの random forest に対する seed の設定は意味がない\n",
    "\n",
    "    model = RuleFitClassifier(rfmode=rfmode,\n",
    "                            tree_generator=tree_generator,\n",
    "                            random_state=random_state,\n",
    "                            exp_rand_tree_size=False)\n",
    "\n",
    "    save_file_path = f'./../../outputs/pima_indian_diabetes_5/fold_{i}/result_rulefit_1.json'\n",
    "    model_name = \"random forest (rulefit)\"\n",
    "    note = None\n",
    "\n",
    "    evaluate_model = EvaluateModelRuleFit(path_discretized=path_discretized,\n",
    "                                model=model,\n",
    "                                name=model_name,\n",
    "                                random_state=random_state,\n",
    "                                n_splits=n_splits,\n",
    "                                train_index=train_index,\n",
    "                                test_index=test_index,\n",
    "                                KB_origin=problem_instance.KB_origin)\n",
    "\n",
    "    evaluate_model.evaluate(save_file_path=save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleFitClassifier そのもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModelRuleFit2:\n",
    "    def __init__(self,\n",
    "                 path_discretized: str,\n",
    "                 model: object,\n",
    "                 KB_origin: List[List[str]],\n",
    "                 random_state: int,\n",
    "                 n_splits: int,\n",
    "                 train_index: np.ndarray,\n",
    "                 test_index: np.ndarray,\n",
    "                 name: str = None,\n",
    "                 note: str = None) -> None:\n",
    "\n",
    "        self.path_discretized = path_discretized\n",
    "        self.model = model\n",
    "        self.KB_origin = KB_origin\n",
    "        self.random_state = random_state \n",
    "        self.n_splits = n_splits\n",
    "\n",
    "        self.train_index = train_index\n",
    "        self.test_index = test_index\n",
    "\n",
    "        self.result_dict = {\n",
    "            'name'     : name,\n",
    "            'note'     : note,\n",
    "            'Accuracy' : None,\n",
    "            'Precision': None,\n",
    "            'Recall'   : None,\n",
    "            'F1-score' : None,\n",
    "            'Auc'      : None,\n",
    "            'len_U'    : None,\n",
    "            'Rules'    : {'violation': 0, 'total': len(self.KB_origin)},\n",
    "            'Rules_detail': {}\n",
    "        }\n",
    "\n",
    "    def calculate_scores(self) -> None:\n",
    "        data = pd.read_csv(self.path_discretized, index_col=0)\n",
    "        data = data.reset_index(drop=True)\n",
    "        X = data.drop('Outcome', axis=1)\n",
    "        y = data['Outcome']\n",
    "        y.replace(0, -1, inplace=True)\n",
    "\n",
    "        X_train, y_train = X.loc[self.train_index, :], y.loc[self.train_index]\n",
    "        X_test, y_test = X.loc[self.test_index, :], y.loc[self.test_index]\n",
    "\n",
    "        feature_names = list(X_train.columns)\n",
    "        X_train = X_train.values\n",
    "        X_test  = X_test.values\n",
    "        y_train = y_train.values\n",
    "        y_test  = y_test.values        \n",
    "        self.model.fit(X_train, y_train, feature_names=feature_names)\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        y_pred_interpreted = np.where(y_pred == 0, -1, y_pred)\n",
    "        \n",
    "        y_pred = self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # 精度等の一般的な評価指標の計算\n",
    "        accuracy = accuracy_score(y_test, y_pred_interpreted)\n",
    "        precision = precision_score(y_test, y_pred_interpreted)\n",
    "        recall = recall_score(y_test, y_pred_interpreted)\n",
    "        f1 = f1_score(y_test, y_pred_interpreted)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        self.result_dict['Accuracy'] = float(accuracy)\n",
    "        self.result_dict['Precision'] = float(precision)\n",
    "        self.result_dict['Recall'] = float(recall)\n",
    "        self.result_dict['F1-score'] = float(f1)\n",
    "        self.result_dict['Auc'] = float(roc_auc)\n",
    "        \n",
    "        # ルール違反\n",
    "        rules_tmp = []\n",
    "        for rule in self.KB_origin:\n",
    "            if \"Outcome\" in rule:\n",
    "                tmp = {}\n",
    "                for idx, item in enumerate(rule):\n",
    "                    if not is_symbol(item):\n",
    "                        if idx == 0 or rule[idx - 1] != '¬':\n",
    "                            tmp[item] = 1\n",
    "                        elif item != \"Outcome\":\n",
    "                            tmp[item] = 0\n",
    "                        else:\n",
    "                            tmp[item] = -1\n",
    "                rules_tmp.append(tmp)\n",
    "\n",
    "        \n",
    "        X_test = pd.DataFrame(X_test, columns=feature_names, index=self.test_index)\n",
    "        y_pred_interpreted = pd.DataFrame(y_pred_interpreted, index=self.test_index)\n",
    "        \n",
    "\n",
    "        for i, rule in enumerate(rules_tmp):\n",
    "            outcome = rule[\"Outcome\"]\n",
    "            condition = \" & \".join([f\"{column} == {value}\" for column, value in rule.items() if column != \"Outcome\"])\n",
    "\n",
    "            tmp = y_pred_interpreted.loc[X_test.query(condition).index]\n",
    "\n",
    "            violation_bool = 1 if int((tmp != outcome).sum().iloc[0]) >= 1 else 0\n",
    "            self.result_dict['Rules']['violation'] += violation_bool\n",
    "            self.result_dict['Rules_detail'][i] = {\n",
    "                'rule': \" \".join(self.KB_origin[i]),\n",
    "                'violation': violation_bool,\n",
    "            }\n",
    "\n",
    "    def save_result_as_json(self, file_path) -> None:\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(self.result_dict, f, indent=4)\n",
    "\n",
    "    def evaluate(self, save_file_path: str = './result_1.json') -> None:\n",
    "        self.calculate_scores()\n",
    "        self.save_result_as_json(file_path=save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_discretized = \"./data/diabetes_discretized.csv\"\n",
    "data = pd.read_csv(path_discretized, index_col=0)\n",
    "data = data.reset_index(drop=True)\n",
    "X = data.drop('Outcome', axis=1)    \n",
    "y = data['Outcome']\n",
    "y.replace(0, -1, inplace=True)\n",
    "random_state = 42\n",
    "n_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    rfmode = 'classify'\n",
    "    tree_generator = RandomForestClassifier(random_state=random_state)\n",
    "    # ここでの random forest に対する seed の設定は意味がない\n",
    "\n",
    "    model = RuleFitClassifier(rfmode=rfmode,\n",
    "                            tree_generator=tree_generator,\n",
    "                            random_state=random_state,\n",
    "                            exp_rand_tree_size=False)\n",
    "\n",
    "    save_file_path = f'./../../outputs/pima_indian_diabetes_5/fold_{i}/result_rulefit_2.json'\n",
    "    model_name = \"RuleFitClassifier\"\n",
    "    note = None\n",
    "\n",
    "    evaluate_model = EvaluateModelRuleFit2(path_discretized=path_discretized,\n",
    "                                model=model,\n",
    "                                name=model_name,\n",
    "                                random_state=random_state,\n",
    "                                n_splits=n_splits,\n",
    "                                train_index=train_index,\n",
    "                                test_index=test_index,\n",
    "                                KB_origin=problem_instance.KB_origin)\n",
    "\n",
    "    evaluate_model.evaluate(save_file_path=save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
